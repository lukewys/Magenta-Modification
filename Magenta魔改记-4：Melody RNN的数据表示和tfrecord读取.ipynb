{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magenta魔改记-4：Melody RNN的数据表示和tfrecord读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文介绍Melody RNN数据表示的具体形式，以及如何读取Melody RNN转换后保存的.tfrecord文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Magenta version:1.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据表示和tfrecord读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "首先，我们以一首最简单的歌曲《小星星》为例。\n",
    "\n",
    "![](pics/star.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一切之前，导入我们需要的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:31.813238Z",
     "start_time": "2019-05-24T02:49:05.692291Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import magenta as mgt\n",
    "import numpy as np\n",
    "\n",
    "#加这行是因为jupyter notebook对tf.app.flags.FLAGS有bug\n",
    "#见https://github.com/tensorflow/tensorflow/issues/17702\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们先把《小星星》的MIDI文件转换成`NoteSequence`，使用上一节介绍的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.010283Z",
     "start_time": "2019-05-24T02:49:31.822240Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converting files in 'Dataset\\raw\\data-representation-example\\'.\n",
      "INFO:tensorflow:0 files converted.\n",
      "INFO:tensorflow:Converted MIDI file Dataset\\raw\\data-representation-example\\star.mid.\n"
     ]
    }
   ],
   "source": [
    "import magenta.scripts.convert_dir_to_note_sequences as cvrt\n",
    "cvrt.FLAGS.input_dir = r'Dataset\\raw\\data-representation-example'\n",
    "cvrt.FLAGS.output_file = r'Dataset\\pre\\data-representation-example.tfrecord'\n",
    "cvrt.FLAGS.recursive = True\n",
    "cvrt.FLAGS.log = 'INFO'\n",
    "unused_argv = ''\n",
    "cvrt.main(unused_argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T09:12:46.296218Z",
     "start_time": "2019-05-19T09:12:46.293217Z"
    },
    "collapsed": true
   },
   "source": [
    "在这之后，我们需要将NoteSequence转换为Melody RNN模型需要的输入形式。\n",
    "\n",
    "与前一节使用的`convert_dir_to_note_sequences.py`类似，我们需要给Melody RNN的数据转换程序输入参数。\n",
    "\n",
    "Melody RNN的数据转换程序为[melody_rnn_create_dataset.py](https://github.com/tensorflow/magenta/blob/master/magenta/models/melody_rnn/melody_rnn_create_dataset.py)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.024287Z",
     "start_time": "2019-05-24T02:49:32.021286Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 首先，我们需要删除在执行convert_dir_to_note_sequences.py转换中定义过的FLAGS，\n",
    "# 否则相同名称的FLAGS会相互冲突。\n",
    "# https://stackoverflow.com/a/51211037/8764874\n",
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.109305Z",
     "start_time": "2019-05-24T02:49:32.038289Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import magenta.models.melody_rnn.melody_rnn_create_dataset as create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.124309Z",
     "start_time": "2019-05-24T02:49:32.121308Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magenta.models.melody_rnn.melody_rnn_config_flags:\n",
      "  --config: Which config to use. Must be one of 'basic', 'lookback', or\n",
      "    'attention'. Mutually exclusive with `--melody_encoder_decoder`.\n",
      "  --generator_description: A description of the generator. Overrides the default\n",
      "    if `--config` is also supplied.\n",
      "  --generator_id: A unique ID for the generator. Overrides the default if\n",
      "    `--config` is also supplied.\n",
      "  --hparams: Comma-separated list of `name=value` pairs. For each pair, the\n",
      "    value of the hyperparameter named `name` is set to `value`. This mapping is\n",
      "    merged with the default hyperparameters.\n",
      "    (default: '')\n",
      "  --melody_encoder_decoder: Which encoder/decoder to use. Must be one of\n",
      "    'onehot', 'lookback', or 'key'. Mutually exclusive with `--config`.\n",
      "\n",
      "magenta.models.melody_rnn.melody_rnn_create_dataset:\n",
      "  --eval_ratio: Fraction of input to set aside for eval set. Partition is\n",
      "    randomly selected.\n",
      "    (default: '0.1')\n",
      "    (a number)\n",
      "  --input: TFRecord to read NoteSequence protos from.\n",
      "  --log: The threshold for what messages will be logged DEBUG, INFO, WARN,\n",
      "    ERROR, or FATAL.\n",
      "    (default: 'INFO')\n",
      "  --output_dir: Directory to write training and eval TFRecord files. The\n",
      "    TFRecord files are populated with  SequenceExample protos.\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n"
     ]
    }
   ],
   "source": [
    "print(create_dataset.FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个值得注意的问题是，在打印出的FLAG中除了有来自`magenta.models.melody_rnn.melody_rnn_create_dataset`的`FLAGS`外，还有来自`magenta.models.melody_rnn.melody_rnn_config_flags`的FLAGS。这是因为在`melody_rnn_create_dataset.py`中，`from magenta.models.melody_rnn import melody_rnn_config_flags`一行导入了来自`melody_rnn_config_flags.py`的FLAGS。对于在jupyter notebook中调试来说，我们可以直接修改`create_dataset.FLAGS`的子类的值。但是如果你想要直接修改python文件并运行的话，不要忘记同时修改`melody_rnn_config_flags.py`中的设置参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们开始设置Melody RNN的配置参数。这里我们先使用`basic_rnn`。我们不需要总去设置所有的参数。有些步骤用不到一些参数，比如在数据转换这步，我们显然就不需要决定网络的规模和LSTM的层数等。同时，有些参数是会根据其他参数的值自动设置。如在`generator_description`、`generator_id`等参数中的描述中，我们可以看到，一旦设置了`config`，就可以不需要设置这些变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们进行设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.155316Z",
     "start_time": "2019-05-24T02:49:32.135311Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_dataset.FLAGS.config = 'basic_rnn'\n",
    "create_dataset.FLAGS.input = 'Dataset\\pre\\data-representation-example.tfrecord'\n",
    "create_dataset.FLAGS.output_dir = 'Dataset\\melody_rnn\\data-representation-example'\n",
    "create_dataset.FLAGS.eval_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.372365Z",
     "start_time": "2019-05-24T02:49:32.166320Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\magenta\\lib\\site-packages\\magenta\\pipelines\\pipeline.py:310: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:Key signatures ignored by TranspositionPipeline.\n",
      "INFO:tensorflow:\n",
      "\n",
      "Completed.\n",
      "\n",
      "INFO:tensorflow:Processed 1 inputs total. Produced 1 outputs.\n",
      "INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_few_pitches: 0\n",
      "INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_long: 0\n",
      "INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_short: 0\n",
      "INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_truncated: 0\n",
      "INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melody_lengths_in_bars:\n",
      "  [10,20): 1\n",
      "INFO:tensorflow:DAGPipeline_MelodyExtractor_training_polyphonic_tracks_discarded: 0\n",
      "INFO:tensorflow:DAGPipeline_RandomPartition_training_melodies_count: 1\n",
      "INFO:tensorflow:DAGPipeline_TranspositionPipeline_training_skipped_due_to_range_exceeded: 0\n",
      "INFO:tensorflow:DAGPipeline_TranspositionPipeline_training_transpositions_generated: 1\n"
     ]
    }
   ],
   "source": [
    "unused_argv = ''\n",
    "create_dataset.main(unused_argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据打印出的信息我们可以发现，Melody RNN的数据清洗工作做得还是相当全面的。在数据转换时，Melody RNN应该是将音乐统一转调，并自动分割，过滤过长或过短的片段。同时，在`Dataset\\pre\\data-representation-example`路径中会生成两个文件`training_melodies.tfrecord`和`eval_melodies.tfrecord`。默认设置下（参数中`eval_ratio`项），验证集为数据集的10％，由于我们现在只有一条数据，因此验证集为空。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来看一下如何读取`.tfrecord`文件，以及在`.tfrecord`文件中，数据是如何存储的："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取tfrecord数据需要建立数据队列。在这里，我们还需要提前定义解析数据的维数。下面定义特征数据的代码可以在[sequence_example_lib.py](https://github.com/tensorflow/magenta/blob/master/magenta/common/sequence_example_lib.py)中的`make_sequence_example`找到，这里给出的是旧版的代码，但一样可以读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.385369Z",
     "start_time": "2019-05-24T02:49:32.383369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_example_file_paths=[r'Dataset\\melody_rnn\\data-representation-example\\training_melodies.tfrecord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:32.446382Z",
     "start_time": "2019-05-24T02:49:32.400371Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-9b3fa15fce01>:1: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow\\python\\training\\input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-9b3fa15fce01>:2: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n"
     ]
    }
   ],
   "source": [
    "file_queue = tf.train.string_input_producer(sequence_example_file_paths)\n",
    "reader = tf.TFRecordReader()\n",
    "read_queue, serialized_example = reader.read(file_queue)\n",
    "\n",
    "sequence_features = {\n",
    "    'inputs': tf.FixedLenSequenceFeature(shape=[38],\n",
    "                                         dtype=tf.float32),\n",
    "    'labels': tf.FixedLenSequenceFeature(shape=[],\n",
    "                                         dtype=tf.int64)}\n",
    "\n",
    "single_queue, sequence = tf.parse_single_sequence_example(\n",
    "    serialized_example, sequence_features=sequence_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于读取tfrecord更详细的内容，你可以查看[这里](https://www.tensorflow.org/tutorials/load_data/tf_records)或[这里](http://www.machinelearninguru.com/deep_learning/tensorflow/basics/tfrecord/tfrecord.html)。tfrecord似乎在新版本中已经逐渐弃用，如果你想从零开始搭建，请了解[tf.data](https://www.tensorflow.org/guide/datasets)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T03:34:14.894239Z",
     "start_time": "2019-05-23T03:34:14.889238Z"
    }
   },
   "source": [
    "因为文件读取常常与多线程结合，因此这里读取时我们需要用到`coord = tf.train.Coordinator()`与`threads = tf.train.start_queue_runners(sess, coord)`等多线程模块。`sequence`在这里相当于一个迭代器，每运行一次返回下一条数据。这里我们只取出一条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:34.943949Z",
     "start_time": "2019-05-24T02:49:32.457386Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:34.991960Z",
     "start_time": "2019-05-24T02:49:34.955954Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-3e321385f29b>:3: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "data_number=1\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess, coord)\n",
    "try:\n",
    "    for i in range (data_number):\n",
    "        seq=sess.run(sequence)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"done\")\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:35.011966Z",
     "start_time": "2019-05-24T02:49:35.007964Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 38)\n",
      "(191,)\n"
     ]
    }
   ],
   "source": [
    "print(seq['inputs'].shape)\n",
    "print(seq['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:35.035970Z",
     "start_time": "2019-05-24T02:49:35.026969Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(seq['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:51:06.576267Z",
     "start_time": "2019-05-24T02:51:06.572266Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  0  0  0 14  0  0  0 21  0  0  0 21  0  0  0 23  0  0  0 23  0  0  0\n",
      " 21  0  0  0  0  0  0  0 19  0  0  0 19  0  0  0 18  0  0  0 18  0  0  0\n",
      " 16  0  0  0 16  0  0  0 14  0  0  0  0  0  0  0 21  0  0  0 21  0  0  0\n",
      " 19  0  0  0 19  0  0  0 18  0  0  0 18  0  0  0 16  0  0  0  0  0  0  0\n",
      " 21  0  0  0 21  0  0  0 19  0  0  0 19  0  0  0 18  0  0  0 18  0  0  0\n",
      " 16  0  0  0  0  0  0  0 14  0  0  0 14  0  0  0 21  0  0  0 21  0  0  0\n",
      " 23  0  0  0 23  0  0  0 21  0  0  0  0  0  0  0 19  0  0  0 19  0  0  0\n",
      " 18  0  0  0 18  0  0  0 16  0  0  0 16  0  0  0 14  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(seq['inputs'],axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T02:49:35.056976Z",
     "start_time": "2019-05-24T02:49:35.053975Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 14  0  0  0 21  0  0  0 21  0  0  0 23  0  0  0 23  0  0  0 21\n",
      "  0  0  0  0  0  0  0 19  0  0  0 19  0  0  0 18  0  0  0 18  0  0  0 16\n",
      "  0  0  0 16  0  0  0 14  0  0  0  0  0  0  0 21  0  0  0 21  0  0  0 19\n",
      "  0  0  0 19  0  0  0 18  0  0  0 18  0  0  0 16  0  0  0  0  0  0  0 21\n",
      "  0  0  0 21  0  0  0 19  0  0  0 19  0  0  0 18  0  0  0 18  0  0  0 16\n",
      "  0  0  0  0  0  0  0 14  0  0  0 14  0  0  0 21  0  0  0 21  0  0  0 23\n",
      "  0  0  0 23  0  0  0 21  0  0  0  0  0  0  0 19  0  0  0 19  0  0  0 18\n",
      "  0  0  0 18  0  0  0 16  0  0  0 16  0  0  0 14  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(seq['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，在`inputs`中，数据以one-hot vector的方式储存，而在`labels`中，数据则直接以数字的方式储存。对比两个序列我们可以发现，`labels`序列是`inputs`序列左移一个时间点。因此，相当于输入$X_1$到$X_t$，输出$X_2$到$X_{t+1}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时，由于我们的乐曲中不含有休止符，因此没有出现“1”代表的`note-off`。由于`basic_rnn`只表示[C3,C5]（MIDI音高为[48,72]）的音高范围，还含有两个特殊标记（`note-off`与`no-event`），因此第一个音C4（MIDI音高为60）则对应着60-48+2=14。之后的数字则以此类推。同时，第一个音“14”的后面有3个“0”可以推断出在这里一个时间点代表着1/4个四分音符的长度。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "magenta",
   "language": "python",
   "name": "magenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
